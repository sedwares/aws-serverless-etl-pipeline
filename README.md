# AWS Serverless ETL Pipeline (S3 â†’ Lambda â†’ Glue â†’ Athena)

This project demonstrates the design of a serverless ETL pipeline on AWS:

- **S3**: stores raw JSON data
- **Lambda**: validates and preprocesses incoming records
- **Glue**: transforms data and writes partitioned output (e.g., Parquet)
- **Athena**: queries the transformed data using SQL

The code in this repository simulates the logic of the Lambda and Glue jobs locally in Python so it can be understood and tested without an AWS account.

---

## ğŸ— Architecture

1. Raw JSON files are uploaded to an S3 bucket.
2. An S3 event triggers a **Lambda function**:
   - Validates required fields
   - Filters out malformed records
   - Writes cleaned data to another S3 location
3. An **AWS Glue ETL job**:
   - Reads cleaned data
   - Normalizes and transforms fields
   - Writes partitioned output for analytics
4. **Athena** queries the curated data.

---

## ğŸ“‚ Project Structure

- `src/lambda_function.py` â€“ Lambda handler and validation logic
- `src/glue_job.py` â€“ Glue-style ETL transformation logic
- `src/utils.py` â€“ Shared helpers
- `data/sample_events.json` â€“ Example input events
- `requirements.txt` â€“ Python dependencies

---

## â–¶ï¸ Running Locally (Simulation)

```bash
pip install -r requirements.txt
python src/lambda_function.py
python src/glue_job.py
